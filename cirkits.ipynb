{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74fa1a5b-9f23-491c-aa86-35170dceb9f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "dlopen(/Users/alexandercheetham/miniconda3/lib/python3.11/site-packages/torch/_C.cpython-311-darwin.so, 0x0002): Symbol not found: __ZN2at3cpu19is_cpu_support_vnniEv\n  Referenced from: <93B052AD-B16C-3D0F-A6FC-DFFBB7CD9584> /Users/alexandercheetham/miniconda3/lib/python3.11/site-packages/torch/lib/libtorch_python.dylib\n  Expected in:     <ADD14A6E-669F-3F53-A802-D8FBD6AA3F40> /Users/alexandercheetham/miniconda3/lib/libtorch_cpu.dylib",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.backends.mps.is_available():\n\u001b[32m      3\u001b[39m     mps_device = torch.device(\u001b[33m\"\u001b[39m\u001b[33mmps\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.11/site-packages/torch/__init__.py:367\u001b[39m\n\u001b[32m    365\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m USE_GLOBAL_DEPS:\n\u001b[32m    366\u001b[39m         _load_global_deps()\n\u001b[32m--> \u001b[39m\u001b[32m367\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_C\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[32m    370\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mSymInt\u001b[39;00m:\n\u001b[32m    371\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    372\u001b[39m \u001b[33;03m    Like an int (including magic methods), but redirects all operations on the\u001b[39;00m\n\u001b[32m    373\u001b[39m \u001b[33;03m    wrapped node. This is used in particular to symbolically record operations\u001b[39;00m\n\u001b[32m    374\u001b[39m \u001b[33;03m    in the symbolic shape workflow.\u001b[39;00m\n\u001b[32m    375\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: dlopen(/Users/alexandercheetham/miniconda3/lib/python3.11/site-packages/torch/_C.cpython-311-darwin.so, 0x0002): Symbol not found: __ZN2at3cpu19is_cpu_support_vnniEv\n  Referenced from: <93B052AD-B16C-3D0F-A6FC-DFFBB7CD9584> /Users/alexandercheetham/miniconda3/lib/python3.11/site-packages/torch/lib/libtorch_python.dylib\n  Expected in:     <ADD14A6E-669F-3F53-A802-D8FBD6AA3F40> /Users/alexandercheetham/miniconda3/lib/libtorch_cpu.dylib"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=mps_device)\n",
    "    print (x)\n",
    "else:\n",
    "    print (\"MPS device not found.\")\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b63f493-a57a-4296-858f-0cd442f8b9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cirkit.templates import data_modalities, utils\n",
    "\n",
    "symbolic_circuit = data_modalities.image_data(\n",
    "    (1, 28, 28),                # The shape of MNIST image, i.e., (num_channels, image_height, image_width)\n",
    "    region_graph='quad-graph',  # Select the structure of the circuit to follow the QuadGraph region graph\n",
    "    input_layer='categorical',  # Use Categorical distributions for the pixel values (0-255) as input layers\n",
    "    num_input_units=64,         # Each input layer consists of 64 Categorical input units\n",
    "    sum_product_layer='cp',     # Use CP sum-product layers, i.e., alternate dense layers with Hadamard product layers\n",
    "    num_sum_units=64,# Each dense sum layer consists of 64 sum units\n",
    "    num_classes=1,\n",
    "    sum_weight_param=utils.Parameterization(\n",
    "        activation='softmax',   # Parameterize the sum weights by using a softmax activation\n",
    "        initialization='normal' # Initialize the sum weights by sampling from a standard normal distribution\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf3eac8-54ed-41c7-bcd7-f4ba3f60bfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print some information\n",
    "print(f'Number of variables: {symbolic_circuit.num_variables}')\n",
    "print()\n",
    "\n",
    "# Print which structural properties the circuit satisfies\n",
    "print(f'Structural properties:')\n",
    "print(f'  - Smoothness: {symbolic_circuit.is_smooth}')\n",
    "print(f'  - Decomposability: {symbolic_circuit.is_decomposable}')\n",
    "print(f'  - Structured-decomposability: {symbolic_circuit.is_structured_decomposable}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b312e0da-a1d3-4880-a7bb-21237ee3130f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Set some seeds\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "# Set the torch device to use\n",
    "device = torch.device('mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c84d57e-e514-4fc9-95c0-1822710a6ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from cirkit.pipeline import compile\n",
    "circuit = compile(symbolic_circuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24abb86d-12ef-42dc-a692-174ff3ae1ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print some statistics\n",
    "num_layers = len(list(symbolic_circuit.layers))\n",
    "print(f\"Number of layers: {num_layers}\")\n",
    "num_parameters = sum(p.numel() for p in circuit.parameters())\n",
    "print(f\"Number of learnable parameters: {num_parameters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd584dc9-16c0-4528-801c-5b5cbbb92768",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "# Load the MNIST data set and data loaders\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # Flatten the images and set pixel values in the [0-255] range\n",
    "    transforms.Lambda(lambda x: (255 * x.view(-1)).long())\n",
    "])\n",
    "data_train = datasets.MNIST('datasets', train=True, download=True, transform=transform)\n",
    "data_test = datasets.MNIST('datasets', train=False, download=True, transform=transform)\n",
    "\n",
    "# Instantiate the training and testing data loaders\n",
    "train_dataloader = DataLoader(data_train, shuffle=True, batch_size=256)\n",
    "test_dataloader = DataLoader(data_test, shuffle=False, batch_size=256)\n",
    "\n",
    "# Initialize a torch optimizer of your choice,\n",
    "#  e.g., Adam, by passing the parameters of the circuit\n",
    "optimizer = optim.Adam(circuit.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb548216-1b48-4187-80ed-2518deb37fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "num_epochs = 10\n",
    "step_idx = 0\n",
    "running_loss = 0.0\n",
    "running_samples = 0\n",
    "\n",
    "# Move the circuit to chosen device\n",
    "circuit = circuit.to(device)\n",
    "\n",
    "for epoch_idx in range(num_epochs):\n",
    "    # Create a tqdm progress bar for the inner loop of the current epoch\n",
    "    epoch_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch_idx+1}/{num_epochs}\")\n",
    "    for i, (batch, _) in enumerate(epoch_bar):\n",
    "        # The circuit expects an input of shape (batch_dim, num_variables)\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        # Compute the log-likelihoods of the batch by evaluating the circuit\n",
    "        log_likelihoods = circuit(batch)\n",
    "\n",
    "        # We take the negated average log-likelihood as loss\n",
    "        loss = -torch.mean(log_likelihoods)\n",
    "        loss.backward()\n",
    "        # Update the parameters of the circuit, as with any other model in PyTorch\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        running_loss += loss.detach() * len(batch)\n",
    "        running_samples += len(batch)\n",
    "        step_idx += 1\n",
    "\n",
    "        if step_idx % 200 == 0:\n",
    "            average_nll = running_loss / running_samples\n",
    "            # Update the tqdm progress bar with the latest average NLL\n",
    "            epoch_bar.set_postfix({\"Average NLL\": f\"{average_nll:.3f}\"})\n",
    "            running_loss = 0.0\n",
    "            running_samples = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0ae631-2a35-4955-a93a-982c35ccde36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_lls = 0.0\n",
    "\n",
    "    # Wrap the test_dataloader with tqdm progress bar\n",
    "    test_bar = tqdm(test_dataloader, desc=\"Testing\")\n",
    "    for batch, _ in test_bar:\n",
    "        # The circuit expects an input of shape (batch_dim, num_channels, num_variables),\n",
    "        # so we unsqueeze a dimension for the channel.\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        # Compute the log-likelihoods of the batch\n",
    "        log_likelihoods = circuit(batch)\n",
    "\n",
    "        # Accumulate the log-likelihoods\n",
    "        test_lls += log_likelihoods.sum().item()\n",
    "        \n",
    "        # Update the progress bar with the current cumulative log-likelihood\n",
    "        test_bar.set_postfix({\"Cumulative LL\": f\"{test_lls:.2f}\"})\n",
    "\n",
    "    # Compute average test log-likelihood and bits per dimension\n",
    "    average_ll = test_lls / len(data_test)\n",
    "    bpd = -average_ll / (28 * 28 * np.log(2.0))\n",
    "    print(f\"Average test LL: {average_ll:.3f}\")\n",
    "    print(f\"Bits per dimension: {bpd:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31428e34-6e24-4c21-a7f3-e55214ce4fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Instantiate the test DataLoader\n",
    "test_dataloader = DataLoader(data_test, shuffle=False, batch_size=256)\n",
    "\n",
    "# Retrieve the first batch from the test DataLoader\n",
    "data_iter = iter(test_dataloader)\n",
    "images, labels = next(data_iter)\n",
    "\n",
    "# Extract the first image and its label from the batch\n",
    "sample_image = images[0]\n",
    "sample_label = labels[0]\n",
    "def generate_and_plot_images(circuit, num_images=5):\n",
    "    \"\"\"\n",
    "    Generates and plots images from the probabilistic circuit.\n",
    "    \n",
    "    Args:\n",
    "        circuit: The probabilistic circuit object.\n",
    "        num_images: Number of images to generate.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(10, 2))\n",
    "    for i in range(num_images):\n",
    "        # Sample from the circuit\n",
    "        input_data = torch.tensor(\n",
    "                np.random.randint(0, 256, size=(1, 784), dtype=np.uint8),\n",
    "                dtype=torch.float32  # make sure dtype is compatible with model\n",
    "            )\n",
    "\n",
    "        input_data = images[i].reshape(1,784)\n",
    "        print(input_data.shape)\n",
    "        sampled_data = circuit.forward(input_data)\n",
    "        print(sampled_data)\n",
    "        # Reshape the sampled data to 28x28 if it's flattened\n",
    "        image = input_data.reshape(28, 28)\n",
    "        # Plot the image\n",
    "        axes[i].imshow(image, cmap='gray')\n",
    "        axes[i].axis('off')\n",
    "    plt.suptitle(\"Generated MNIST-like Images\")\n",
    "    plt.show()\n",
    "\n",
    "# Assuming 'circuit' is your trained probabilistic circuit\n",
    "generate_and_plot_images(circuit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811f7a27-d09b-4996-b8d6-34b3cc6553e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Generate random data with values between 0 and 255, and shape (1, 28, 28)\n",
    "random_data = np.random.randint(0, 256, size=(1, 28, 28), dtype=np.uint8)\n",
    "\n",
    "# Normalize the data to the range [0, 1] if required by the model\n",
    "normalized_data = random_data / 255.0\n",
    "\n",
    "# Reshape the data to match the model's expected input shape (B, D)\n",
    "reshaped_data = normalized_data.reshape(1, 784)  # 1 sample, 784 features\n",
    "\n",
    "# Convert the NumPy array to a PyTorch tensor\n",
    "input_tensor = torch.tensor(reshaped_data, dtype=torch.float32)\n",
    "\n",
    "# Pass the tensor to the model\n",
    "output = circuit.forward(input_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5ea794-ed67-465a-bc79-3b8ed2e18830",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde03111-6549-4877-b909-6d1e5366d0d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
