{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bedfed0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2025-08-12 14:52:08.531394] --- Benchmarking ORIGINAL model ---\n",
      "Compiled circuit with rank None on device cuda\n",
      "\n",
      "--- NLL Calculation for Original Model ---\n",
      "Batch shape: torch.Size([64, 784])\n",
      "Normalizer Z_bok tensor([-78.2435+0.j], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Circuit Output shape: torch.Size([64, 1, 1])\n",
      "NLL shape: torch.Size([64, 1, 1])\n",
      "Average NLL for the Original batch: 1270.25927734375\n",
      "\n",
      "[2025-08-12 14:52:14.713304] --- Benchmarking NYSTRÖM model ---\n",
      "Compiled circuit with rank 256 on device cuda\n",
      "[2025-08-12 14:52:35.460575] Sum Layer Weight Sync Progress: 24% (262/1049)\n",
      "[2025-08-12 14:52:39.892844] Sum Layer Weight Sync Progress: 49% (524/1049)\n",
      "[2025-08-12 14:52:44.311997] Sum Layer Weight Sync Progress: 74% (786/1049)\n",
      "[2025-08-12 14:52:48.841489] Sum Layer Weight Sync Progress: 99% (1048/1049)\n",
      "[2025-08-12 14:52:48.844181] Sum Layer Weight Sync Progress: 100% (1049/1049)\n",
      "\n",
      "--- Syncing Categorical Layer (logits/probs) by Parameter Name ---\n",
      "--- Finished syncing. Copied 784 categorical parameters. ---\n",
      "\n",
      "\n",
      "--- NLL Calculation for Nyström Approximated Model ---\n",
      "Normalizer Z_bok_nys: tensor([-78.8499+7.0792e-10j], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Nyström Output shape: torch.Size([64, 1, 1])\n",
      "NLL Nyström shape: torch.Size([64, 1, 1])\n",
      "Average NLL for the Nyström batch: 1279.5888671875\n",
      "1.62022864818573 1.6321285963058472 0.011899948120117188\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from datetime import datetime\n",
    "import os\n",
    "import time\n",
    "import faulthandler\n",
    "\n",
    "# Assuming the necessary components from cirkit and your project are available\n",
    "from src.circuit_types import CIRCUIT_BUILDERS\n",
    "from cirkit.symbolic.circuit import Circuit\n",
    "from cirkit.pipeline import PipelineContext, compile as compile_circuit\n",
    "import cirkit.symbolic.functional as SF\n",
    "from cirkit.backend.torch.queries import IntegrateQuery\n",
    "from cirkit.utils.scope import Scope\n",
    "from cirkit.backend.torch.layers import TorchSumLayer\n",
    "from cirkit.backend.torch.layers import TorchCategoricalLayer\n",
    "from src.nystromlayer import NystromSumLayer\n",
    "\n",
    "# --- Helper Functions ---\n",
    "\n",
    "def compile_symbolic(circuit: Circuit, *, device: str, rank: int | None = None, opt: bool = False):\n",
    "    \"\"\"Compile a symbolic circuit with optional Nyström optimization.\"\"\"\n",
    "    ctx = PipelineContext(\n",
    "        backend=\"torch\",\n",
    "        semiring=\"complex-lse-sum\",\n",
    "        fold=False,\n",
    "        optimize=opt,\n",
    "        nystrom_rank=rank,\n",
    "    )\n",
    "    compiled = compile_circuit(circuit, ctx, nystrom_rank=rank).to(device).eval()\n",
    "    print(f\"Compiled circuit with rank {rank} on device {device}\", flush=True)\n",
    "    return compiled\n",
    "\n",
    "\n",
    "def sync_sumlayer_weights(\n",
    "    original: nn.Module, nystrom: nn.Module, *, pivot: str = \"uniform\", rank: int | None = None\n",
    ") -> None:\n",
    "    \"\"\"Copy weights from ``original`` to ``nystrom`` for matching layers.\"\"\"\n",
    "    # Sync for TorchSumLayer and NystromSumLayer\n",
    "    orig_sum_layers = [m for m in original.modules() if isinstance(m, TorchSumLayer)]\n",
    "    nys_sum_layers = [m for m in nystrom.modules() if isinstance(m, NystromSumLayer)]\n",
    "    if len(orig_sum_layers) != len(nys_sum_layers):\n",
    "        print(f\"{len(orig_sum_layers)},{len(nys_sum_layers)}\")\n",
    "        raise ValueError(\"Sum layer count mismatch when syncing weights\")\n",
    "\n",
    "    faulthandler.enable(all_threads=True)\n",
    "    total_sum = len(orig_sum_layers)\n",
    "    interval_sum = max(1, total_sum // 4)\n",
    "\n",
    "    for i, (o, n) in enumerate(zip(orig_sum_layers, nys_sum_layers), start=1):\n",
    "        start = time.perf_counter()\n",
    "        faulthandler.dump_traceback_later(30, repeat=False)\n",
    "        try:\n",
    "            if rank is not None:\n",
    "                n.rank = int(rank)\n",
    "                n.rank_param.data.fill_(n.rank)\n",
    "            n.pivot = pivot\n",
    "            n._build_factors_from(o)\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.synchronize()\n",
    "        except Exception as e:\n",
    "            print(f\"[{datetime.now()}] Exception on sum layer {i}/{total_sum}: {e}\", flush=True)\n",
    "            raise\n",
    "        finally:\n",
    "            faulthandler.cancel_dump_traceback_later()\n",
    "\n",
    "        if i % interval_sum == 0 or i == total_sum:\n",
    "            pct = int(100 * i / total_sum)\n",
    "            print(f\"[{datetime.now()}] Sum Layer Weight Sync Progress: {pct}% ({i}/{total_sum})\", flush=True)\n",
    "\n",
    "    # --- Step 2: Sync Categorical Layers (NEW & IMPROVED LOGIC) ---\n",
    "    print(\"\\n--- Syncing Categorical Layer (logits/probs) by Parameter Name ---\", flush=True)\n",
    "\n",
    "    # Create a dictionary of the original model's parameters for fast lookup.\n",
    "    # This is the 'a' from your working snippet.\n",
    "    original_params = dict(original.named_parameters())\n",
    "\n",
    "    copied_params_count = 0\n",
    "    with torch.no_grad():\n",
    "        # Iterate through the Nystrom model's named parameters.\n",
    "        for name, nys_param in nystrom.named_parameters():\n",
    "            # Check if the parameter is a logit or probability tensor by its name.\n",
    "            if 'logits' in name or 'probs' in name:\n",
    "                if name in original_params:\n",
    "                    # Use the proven method: copy the data directly.\n",
    "                    # .copy_() is a safe, in-place operation.\n",
    "                    orig_param = original_params[name]\n",
    "                    nys_param.data.copy_(orig_param.data)\n",
    "                    copied_params_count += 1\n",
    "                else:\n",
    "                    # This warning is helpful for debugging architecture mismatches.\n",
    "                    print(f\"Warning: Parameter '{name}' found in Nystrom model but not in original.\")\n",
    "    \n",
    "    print(f\"--- Finished syncing. Copied {copied_params_count} categorical parameters. ---\\n\",)\n",
    "def complex_logsumexp(z, dim):\n",
    "    \"\"\"Numerically stable complex log-sum-exp, corrected for broadcasting.\"\"\"\n",
    "    # Keep dimension for stable subtraction\n",
    "    m = z.real.max(dim=dim, keepdim=True).values\n",
    "    \n",
    "    # Calculate the log-sum-exp part\n",
    "    log_sum_exp_part = (z - m).exp().sum(dim=dim).log()\n",
    "    \n",
    "    # Squeeze `m` to match the shape of `log_sum_exp_part` for correct addition\n",
    "    return log_sum_exp_part + m.squeeze(dim)\n",
    "\n",
    "# --- Setup and Data Loading ---\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "physical_batch_size = 64\n",
    "n_input = 28 * 28\n",
    "\n",
    "# Build the symbolic circuit\n",
    "builder = CIRCUIT_BUILDERS[\"MNIST\"]\n",
    "builder_kwargs = {\"num_input_units\": 16, \"num_sum_units\": 16, \"region_graph\": \"quad-tree-4\"}\n",
    "symbolic = builder(**builder_kwargs)\n",
    "squared = SF.multiply(symbolic, symbolic)\n",
    "\n",
    "# Prepare the MNIST test data\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda x: (255 * x.view(-1)).long())])\n",
    "data_test = datasets.MNIST(root=\"./.data\", train=False, download=True, transform=transform)\n",
    "test_dataloader = DataLoader(data_test, shuffle=False, batch_size=physical_batch_size)\n",
    "batch, _ = next(iter(test_dataloader))\n",
    "batch = batch.to(device)\n",
    "\n",
    "# --- 1. Original Model NLL Calculation ---\n",
    "\n",
    "print(f\"\\n[{datetime.now()}] --- Benchmarking ORIGINAL model ---\", flush=True)\n",
    "original_circuit = compile_symbolic(squared, device=device, rank=None, opt=False)\n",
    "\n",
    "# Load the pretrained model from cache\n",
    "units = 16\n",
    "cache_path = f\"./model_cache/checkpoints/mnist_{units}_{units}_epoch10.pt\"\n",
    "if os.path.exists(cache_path):\n",
    "    original_circuit.load_state_dict(torch.load(cache_path, map_location=device)[\"model_state_dict\"])\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Checkpoint not found at {cache_path}\")\n",
    "\n",
    "# Calculate Normalizer Z\n",
    "iq_orig = IntegrateQuery(original_circuit)\n",
    "Z_bok_orig = iq_orig(batch, integrate_vars=Scope(original_circuit.scope))\n",
    "\n",
    "\n",
    "# Get circuit output and compute NLL\n",
    "circuit_output_real = original_circuit(batch).real\n",
    "nll_orig = -(circuit_output_real - Z_bok_orig[0][0].real)\n",
    "\n",
    "print(\"\\n--- NLL Calculation for Original Model ---\")\n",
    "print(f\"Batch shape: {batch.shape}\")\n",
    "print(f\"Normalizer Z_bok {Z_bok_orig[0][0]}\")\n",
    "print(f\"Circuit Output shape: {circuit_output_real.shape}\")\n",
    "print(f\"NLL shape: {nll_orig.shape}\")\n",
    "print(f\"Average NLL for the Original batch: {nll_orig.mean()}\")\n",
    "\n",
    "# --- 2. Nyström Approximated Model NLL Calculation ---\n",
    "\n",
    "print(f\"\\n[{datetime.now()}] --- Benchmarking NYSTRÖM model ---\", flush=True)\n",
    "nystrom_circuit = compile_symbolic(squared, device=device, rank=256, opt=True)\n",
    "\n",
    "\n",
    "# Synchronize weights from the trained original model\n",
    "sync_sumlayer_weights(original_circuit, nystrom_circuit, pivot=\"uniform\", rank=77)\n",
    "\n",
    "# Calculate Normalizer Z for the Nystrom model\n",
    "iq_nys = IntegrateQuery(nystrom_circuit)\n",
    "Z_bok_nys = iq_nys(batch, integrate_vars=Scope(nystrom_circuit.scope))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Get circuit output and compute NLL, APPLYING THE SAME FIX\n",
    "nystrom_output_real = nystrom_circuit(batch).real\n",
    "nll_nys = -(nystrom_output_real - Z_bok_nys[0][0].real)\n",
    "\n",
    "print(\"\\n--- NLL Calculation for Nyström Approximated Model ---\")\n",
    "print(f\"Normalizer Z_bok_nys: {Z_bok_nys[0][0]}\")\n",
    "print(f\"Nyström Output shape: {nystrom_output_real.shape}\")\n",
    "print(f\"NLL Nyström shape: {nll_nys.shape}\")\n",
    "print(f\"Average NLL for the Nyström batch: {nll_nys.mean()}\")\n",
    "orig_bpd = (nll_orig.mean() / (784 )).item()\n",
    "nystrom_bpd = (nll_nys.mean() / (784)).item()\n",
    "bpd_diff = abs(orig_bpd - nystrom_bpd)\n",
    "print(orig_bpd,nystrom_bpd,bpd_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60b20cec-8e65-4b3f-8d9b-2c9e3097d143",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_full_model_output(\n",
    "    original_model: nn.Module,\n",
    "    nystrom_model: nn.Module,\n",
    "    verification_batch: torch.Tensor,\n",
    "    *,\n",
    "    use_allclose: bool = True,\n",
    "    rtol: float = 1e-5,\n",
    "    atol: float = 1e-6\n",
    ") -> bool:\n",
    "    \"\"\"\n",
    "    Verifies that two models produce the same output for a given input batch.\n",
    "\n",
    "    This is the most reliable way to check if weight synchronization was successful.\n",
    "\n",
    "    Args:\n",
    "        original_model: The original, trained model.\n",
    "        nystrom_model: The Nystrom-approximated model.\n",
    "        verification_batch: A batch of real data for testing.\n",
    "        use_allclose: If True, use torch.allclose for float comparison.\n",
    "        rtol: Relative tolerance for torch.allclose.\n",
    "        atol: Absolute tolerance for torch.allclose.\n",
    "\n",
    "    Returns:\n",
    "        True if the outputs are identical within the given tolerance.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Verifying Full Model Output Post-Sync ---\")\n",
    "    original_model.eval()\n",
    "    nystrom_model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        original_output = original_model(verification_batch)\n",
    "        nystrom_output = nystrom_model(verification_batch)\n",
    "\n",
    "    # The output is complex, so torch.allclose is the correct tool\n",
    "    if use_allclose:\n",
    "        are_outputs_equal = torch.allclose(original_output, nystrom_output, rtol=rtol, atol=atol)\n",
    "    else:\n",
    "        are_outputs_equal = torch.equal(original_output, nystrom_output)\n",
    "\n",
    "    if not are_outputs_equal:\n",
    "        print(\"Verification FAILED: Full model outputs do not match.\")\n",
    "        # Provide debug info if they don't match\n",
    "        real_diff = torch.abs(original_output.real - nystrom_output.real).sum()\n",
    "        imag_diff = torch.abs(original_output.imag - nystrom_output.imag).sum()\n",
    "        print(f\"Sum of absolute difference (real part): {real_diff.item()}\")\n",
    "        print(f\"Sum of absolute difference (imag part): {imag_diff.item()}\")\n",
    "    else:\n",
    "        print(\"Verification PASSED: Full model outputs are identical (within tolerance).\")\n",
    "\n",
    "    return are_outputs_equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efe9ccca-83c0-4593-a92d-37314fcaad35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2025-08-12 14:20:09.670681] --- Step 1: Setting up ORIGINAL model ---\n",
      "Compiled circuit with rank None on device cuda\n",
      "\n",
      "[2025-08-12 14:20:14.016409] --- Step 2: Setting up NYSTRÖM model and syncing weights ---\n",
      "Compiled circuit with rank 256 on device cuda\n",
      "[2025-08-12 14:20:17.542480] Sum Layer Weight Sync Progress: 24% (262/1049)\n",
      "[2025-08-12 14:20:18.194550] Sum Layer Weight Sync Progress: 49% (524/1049)\n",
      "[2025-08-12 14:20:18.843847] Sum Layer Weight Sync Progress: 74% (786/1049)\n",
      "[2025-08-12 14:20:19.496502] Sum Layer Weight Sync Progress: 99% (1048/1049)\n",
      "[2025-08-12 14:20:19.498726] Sum Layer Weight Sync Progress: 100% (1049/1049)\n",
      "[2025-08-12 14:20:19.589956] Categorical Layer Sync Progress: 25% (196/784)\n",
      "[2025-08-12 14:20:19.651380] Categorical Layer Sync Progress: 50% (392/784)\n",
      "[2025-08-12 14:20:19.712486] Categorical Layer Sync Progress: 75% (588/784)\n",
      "[2025-08-12 14:20:19.773617] Categorical Layer Sync Progress: 100% (784/784)\n",
      "\n",
      "[2025-08-12 14:20:19.773983] --- Step 3: Verifying layer outputs post-sync ---\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from datetime import datetime\n",
    "import os\n",
    "import time\n",
    "import faulthandler\n",
    "from typing import Type\n",
    "\n",
    "# Assuming the necessary components from cirkit and your project are available\n",
    "from src.circuit_types import CIRCUIT_BUILDERS\n",
    "from cirkit.symbolic.circuit import Circuit\n",
    "from cirkit.pipeline import PipelineContext, compile as compile_circuit\n",
    "import cirkit.symbolic.functional as SF\n",
    "from cirkit.backend.torch.queries import IntegrateQuery\n",
    "from cirkit.utils.scope import Scope\n",
    "from cirkit.backend.torch.layers import TorchSumLayer\n",
    "from cirkit.backend.torch.layers.input import TorchCategoricalLayer # Corrected import path\n",
    "from src.nystromlayer import NystromSumLayer\n",
    "\n",
    "# --- Helper Functions (Your existing functions) ---\n",
    "\n",
    "def compile_symbolic(circuit: Circuit, *, device: str, rank: int | None = None, opt: bool = False):\n",
    "    \"\"\"Compile a symbolic circuit with optional Nyström optimization.\"\"\"\n",
    "    ctx = PipelineContext(\n",
    "        backend=\"torch\",\n",
    "        semiring=\"complex-lse-sum\",\n",
    "        fold=False,\n",
    "        optimize=opt,\n",
    "        nystrom_rank=rank,\n",
    "    )\n",
    "    compiled = compile_circuit(circuit, ctx, nystrom_rank=rank).to(device).eval()\n",
    "    print(f\"Compiled circuit with rank {rank} on device {device}\", flush=True)\n",
    "    return compiled\n",
    "\n",
    "\n",
    "def sync_sumlayer_weights(\n",
    "    original: nn.Module, nystrom: nn.Module, *, pivot: str = \"uniform\", rank: int | None = None\n",
    ") -> None:\n",
    "    \"\"\"Copy weights from ``original`` to ``nystrom`` for matching layers.\"\"\"\n",
    "    # Sync for TorchSumLayer and NystromSumLayer\n",
    "    orig_sum_layers = [m for m in original.modules() if isinstance(m, TorchSumLayer)]\n",
    "    nys_sum_layers = [m for m in nystrom.modules() if isinstance(m, NystromSumLayer)]\n",
    "    if len(orig_sum_layers) != len(nys_sum_layers):\n",
    "        print(f\"{len(orig_sum_layers)},{len(nys_sum_layers)}\")\n",
    "        raise ValueError(\"Sum layer count mismatch when syncing weights\")\n",
    "\n",
    "    faulthandler.enable(all_threads=True)\n",
    "    total_sum = len(orig_sum_layers)\n",
    "    interval_sum = max(1, total_sum // 4)\n",
    "\n",
    "    for i, (o, n) in enumerate(zip(orig_sum_layers, nys_sum_layers), start=1):\n",
    "        start = time.perf_counter()\n",
    "        faulthandler.dump_traceback_later(30, repeat=False)\n",
    "        try:\n",
    "            if rank is not None:\n",
    "                n.rank = int(rank)\n",
    "                n.rank_param.data.fill_(n.rank)\n",
    "            n.pivot = pivot\n",
    "            n._build_factors_from(o)\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.synchronize()\n",
    "        except Exception as e:\n",
    "            print(f\"[{datetime.now()}] Exception on sum layer {i}/{total_sum}: {e}\", flush=True)\n",
    "            raise\n",
    "        finally:\n",
    "            faulthandler.cancel_dump_traceback_later()\n",
    "\n",
    "        if i % interval_sum == 0 or i == total_sum:\n",
    "            pct = int(100 * i / total_sum)\n",
    "            print(f\"[{datetime.now()}] Sum Layer Weight Sync Progress: {pct}% ({i}/{total_sum})\", flush=True)\n",
    "\n",
    "    # Sync for TorchCategoricalLayer\n",
    "    orig_cat_layers = [m for m in original.modules() if isinstance(m, TorchCategoricalLayer)]\n",
    "    nys_cat_layers = [m for m in nystrom.modules() if isinstance(m, TorchCategoricalLayer)]\n",
    "\n",
    "    if len(orig_cat_layers) != len(nys_cat_layers):\n",
    "        raise ValueError(\"Categorical layer count mismatch when syncing weights\")\n",
    "\n",
    "    total_cat = len(orig_cat_layers)\n",
    "    interval_cat = max(1, total_cat // 4)\n",
    "\n",
    "    for i, (o, n) in enumerate(zip(orig_cat_layers, nys_cat_layers), start=1):\n",
    "        # In TorchCategoricalLayer, exactly one of logits or probs is not None.\n",
    "        # The TorchParameter object must be called to return the underlying tensor.\n",
    "        if o.logits is not None and n.logits is not None:\n",
    "            n.logits().data.copy_(o.logits().data)\n",
    "        elif o.probs is not None and n.probs is not None:\n",
    "            n.probs().data.copy_(o.probs().data)\n",
    "\n",
    "        if i % interval_cat == 0 or i == total_cat:\n",
    "            pct = int(100 * i / total_cat)\n",
    "            print(f\"[{datetime.now()}] Categorical Layer Sync Progress: {pct}% ({i}/{total_cat})\", flush=True)\n",
    "\n",
    "# --- NEW: VERIFICATION FUNCTION ---\n",
    "# (Paste the verify_first_layer_output function definition from above here)\n",
    "\n",
    "\n",
    "# --- Setup and Data Loading ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "physical_batch_size = 64\n",
    "n_input = 28 * 28\n",
    "builder_kwargs = {\"num_input_units\": 4, \"num_sum_units\": 4, \"region_graph\": \"quad-tree-4\"}\n",
    "\n",
    "# --- 1. Original Model Setup ---\n",
    "print(f\"\\n[{datetime.now()}] --- Step 1: Setting up ORIGINAL model ---\", flush=True)\n",
    "builder = CIRCUIT_BUILDERS[\"MNIST\"]\n",
    "symbolic = builder(**builder_kwargs)\n",
    "squared = SF.multiply(symbolic, symbolic)\n",
    "original_circuit = compile_symbolic(squared, device=device, rank=None, opt=False)\n",
    "\n",
    "# Load pretrained weights\n",
    "units = builder_kwargs[\"num_input_units\"]\n",
    "cache_path = f\"./model_cache/checkpoints/mnist_{units}_{units}_epoch10.pt\"\n",
    "if os.path.exists(cache_path):\n",
    "    original_circuit.load_state_dict(torch.load(cache_path, map_location=device)[\"model_state_dict\"])\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Checkpoint not found at {cache_path}. Cannot proceed.\")\n",
    "\n",
    "# --- 2. Nyström Model Setup and Weight Sync ---\n",
    "print(f\"\\n[{datetime.now()}] --- Step 2: Setting up NYSTRÖM model and syncing weights ---\", flush=True)\n",
    "nystrom_circuit = compile_symbolic(squared, device=device, rank=256, opt=True)\n",
    "sync_sumlayer_weights(original_circuit, nystrom_circuit, pivot=\"uniform\", rank=256)\n",
    "\n",
    "\n",
    "# --- 3. Verification of Layer Outputs (NEW STEP) ---\n",
    "print(f\"\\n[{datetime.now()}] --- Step 3: Verifying layer outputs post-sync ---\", flush=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3d63178-9454-4f22-af88-54671e9df367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2025-08-12 14:25:39.262236] --- Step 3: Loading data for verification ---\n",
      "\n",
      "--- Verifying Full Model Output Post-Sync ---\n",
      "Verification FAILED: Full model outputs do not match.\n",
      "Sum of absolute difference (real part): 501823.9375\n",
      "Sum of absolute difference (imag part): 3.6545700493606503e-11\n",
      "\n",
      "[2025-08-12 14:25:40.570812] --- Step 4: Calculating NLL using the same batch ---\n",
      "\n",
      "--- Final NLL and BPD Results ---\n",
      "Average NLL for the Original batch: 1347.3545\n",
      "Average NLL for the Nyström batch: 5656.5347\n",
      "Original BPD: 0.8593\n",
      "Nystrom BPD:  3.6075\n",
      "BPD Difference: 2.748202\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Load Real Data and Verify Model Outputs ---\n",
    "print(f\"\\n[{datetime.now()}] --- Step 3: Loading data for verification ---\", flush=True)\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda x: (255 * x.view(-1)).long())])\n",
    "data_test = datasets.MNIST(root=\"./.data\", train=False, download=True, transform=transform)\n",
    "test_dataloader = DataLoader(data_test, shuffle=False, batch_size=physical_batch_size)\n",
    "verification_batch, _ = next(iter(test_dataloader))\n",
    "verification_batch = verification_batch.to(device)\n",
    "\n",
    "# Use the loaded batch to verify the full models are equivalent\n",
    "verify_full_model_output(original_circuit, nystrom_circuit, verification_batch)\n",
    "\n",
    "# --- 4. NLL Calculation and Comparison ---\n",
    "print(f\"\\n[{datetime.now()}] --- Step 4: Calculating NLL using the same batch ---\", flush=True)\n",
    "# NLL for Original Model\n",
    "iq_orig = IntegrateQuery(original_circuit)\n",
    "Z_bok_orig = iq_orig(verification_batch, integrate_vars=Scope(original_circuit.scope))\n",
    "circuit_output_real = original_circuit(verification_batch).real\n",
    "nll_orig = -(circuit_output_real - Z_bok_orig[0][0].real)\n",
    "\n",
    "# NLL for Nystrom Model\n",
    "iq_nys = IntegrateQuery(nystrom_circuit)\n",
    "Z_bok_nys = iq_nys(verification_batch, integrate_vars=Scope(nystrom_circuit.scope))\n",
    "nystrom_output_real = nystrom_circuit(verification_batch).real\n",
    "nll_nys = -(nystrom_output_real - Z_bok_nys[0][0].real)\n",
    "\n",
    "# --- Final Results ---\n",
    "print(\"\\n--- Final NLL and BPD Results ---\")\n",
    "print(f\"Average NLL for the Original batch: {nll_orig.mean():.4f}\")\n",
    "print(f\"Average NLL for the Nyström batch: {nll_nys.mean():.4f}\")\n",
    "\n",
    "orig_bpd = (nll_orig.mean() / (n_input * 2)).item() # Squared model has 2x input vars\n",
    "nystrom_bpd = (nll_nys.mean() / (n_input * 2)).item()\n",
    "bpd_diff = abs(orig_bpd - nystrom_bpd)\n",
    "\n",
    "print(f\"Original BPD: {orig_bpd:.4f}\")\n",
    "print(f\"Nystrom BPD:  {nystrom_bpd:.4f}\")\n",
    "print(f\"BPD Difference: {bpd_diff:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d97e3fb7-4de6-4fec-b48e-dbb969a5eff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 784])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, label = next(iter(DataLoader(data_test, batch_size=1)))\n",
    "img.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
